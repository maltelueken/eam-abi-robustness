{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import os\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    # set this to \"torch\", \"tensorflow\", or \"jax\"\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "import numpy as np\n",
    "import bayesflow as bf\n",
    "import keras\n",
    "import pydmc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.61 ms ± 147 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "dat = pydmc.Sim(full_data=False, n_trls=500, n_trls_data=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator_fun():\n",
    "    params = pydmc.Prms(drc=RNG.uniform(0.2, 0.6),  tau=RNG.gamma(shape=12, scale=6))\n",
    "    data = pydmc.Sim(prms=params, n_trls=500, n_trls_data=500)\n",
    "    return {\"mu_c\": params.drc, \"tau\": params.tau, \"x\": np.array(data.data).reshape(500, 4), \"num_obs\": 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = bf.simulators.CompositeLambdaSimulator(sample_fns=[simulator_fun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_batch = simulator.sample((64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47033253],\n",
       "       [0.5197864 ],\n",
       "       [0.23149021],\n",
       "       [0.2678477 ],\n",
       "       [0.24215427],\n",
       "       [0.3860477 ],\n",
       "       [0.43872896],\n",
       "       [0.37709022],\n",
       "       [0.28526294],\n",
       "       [0.30734614],\n",
       "       [0.38688353],\n",
       "       [0.31452733],\n",
       "       [0.38720763],\n",
       "       [0.23161373],\n",
       "       [0.56218994],\n",
       "       [0.5335588 ],\n",
       "       [0.29134023],\n",
       "       [0.33474112],\n",
       "       [0.3005375 ],\n",
       "       [0.3702391 ],\n",
       "       [0.4341549 ],\n",
       "       [0.5775771 ],\n",
       "       [0.40757254],\n",
       "       [0.2965027 ],\n",
       "       [0.32883912],\n",
       "       [0.20539059],\n",
       "       [0.43563   ],\n",
       "       [0.35172117],\n",
       "       [0.30428642],\n",
       "       [0.48115647],\n",
       "       [0.28740823],\n",
       "       [0.27878287],\n",
       "       [0.58720326],\n",
       "       [0.44809264],\n",
       "       [0.28301612],\n",
       "       [0.40218595],\n",
       "       [0.29873008],\n",
       "       [0.35341045],\n",
       "       [0.53782016],\n",
       "       [0.56202984],\n",
       "       [0.45619163],\n",
       "       [0.25061688],\n",
       "       [0.42512283],\n",
       "       [0.35656154],\n",
       "       [0.22077344],\n",
       "       [0.34798983],\n",
       "       [0.29228386],\n",
       "       [0.22937801],\n",
       "       [0.579261  ],\n",
       "       [0.5120752 ],\n",
       "       [0.32505482],\n",
       "       [0.42484123],\n",
       "       [0.5261144 ],\n",
       "       [0.5357283 ],\n",
       "       [0.23500927],\n",
       "       [0.2720763 ],\n",
       "       [0.4869661 ],\n",
       "       [0.49707535],\n",
       "       [0.5588598 ],\n",
       "       [0.39592072],\n",
       "       [0.4949971 ],\n",
       "       [0.27120814],\n",
       "       [0.40638798],\n",
       "       [0.31356105]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_batch[\"mu_c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 4, 500)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_batch[\"x\"].reshape((64, 4, 500)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter = bf.ContinuousApproximator.build_data_adapter(\n",
    "    inference_variables=[\"mu_c\", \"tau\"],\n",
    "    inference_conditions=[\"num_obs\"],\n",
    "    summary_variables=[\"x\"],\n",
    "    transforms=[\n",
    "        bf.data_adapters.transforms.Standardize([\"mu_c\", \"tau\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = bf.networks.SetTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_network = bf.networks.FlowMatching(\n",
    "    subnet=\"mlp\",\n",
    "    subnet_kwargs=dict(\n",
    "        depth=6,\n",
    "        width=256,\n",
    "    ),\n",
    "    use_optimal_transport=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator = bf.ContinuousApproximator(\n",
    "    summary_network=summary_network,\n",
    "    inference_network=inference_network,\n",
    "    data_adapter=data_adapter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Building dataset from simulator instance of CompositeLambdaSimulator.\n",
      "INFO:bayesflow:Using 32 data loading workers.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 522ms/step - loss: 5.7747 - loss/inference_loss: 5.7747\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 524ms/step - loss: 1.5624 - loss/inference_loss: 1.5624\n",
      "Epoch 3/5\n",
      "\u001b[1m 97/500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 566ms/step - loss: 1.5496 - loss/inference_loss: 1.5496"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mapproximator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# memory_budget=\"8 GiB\",\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimulator\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/eam-abi-robustness/lib/python3.10/site-packages/bayesflow/approximators/continuous_approximator.py:109\u001b[0m, in \u001b[0;36mContinuousApproximator.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/eam-abi-robustness/lib/python3.10/site-packages/bayesflow/approximators/approximator.py:84\u001b[0m, in \u001b[0;36mApproximator.fit\u001b[0;34m(self, dataset, simulator, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     mock_data \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap_structure(keras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mconvert_to_tensor, mock_data)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_from_data(mock_data)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/eam-abi-robustness/lib/python3.10/site-packages/bayesflow/approximators/backend_approximators/backend_approximator.py:22\u001b[0m, in \u001b[0;36mBackendApproximator.fit\u001b[0;34m(self, dataset, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, dataset: keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mPyDataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfilter_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/eam-abi-robustness/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Repositories/eam-abi-robustness/lib/python3.10/site-packages/keras/src/backend/jax/trainer.py:433\u001b[0m, in \u001b[0;36mJAXTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    424\u001b[0m (\n\u001b[1;32m    425\u001b[0m     trainable_variables,\n\u001b[1;32m    426\u001b[0m     non_trainable_variables,\n\u001b[1;32m    427\u001b[0m     optimizer_variables,\n\u001b[1;32m    428\u001b[0m     metrics_variables,\n\u001b[1;32m    429\u001b[0m ) \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# Setting _jax_state enables callbacks to force a state sync\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# if they need to.\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jax_state\u001b[49m \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m: trainable_variables,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_trainable_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m: non_trainable_variables,\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer_variables,\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics_variables,\n\u001b[1;32m    438\u001b[0m }\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[1;32m    441\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n",
      "File \u001b[0;32m~/Repositories/eam-abi-robustness/lib/python3.10/site-packages/keras/src/layers/layer.py:1393\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_tracker()\n\u001b[1;32m   1392\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracker\u001b[38;5;241m.\u001b[39mtrack(value)\n\u001b[0;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = approximator.fit(\n",
    "    epochs=5,\n",
    "    num_batches=500,\n",
    "    batch_size=64,\n",
    "    # memory_budget=\"8 GiB\",\n",
    "    simulator=simulator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.70952738e+02, 3.94759226e+02, 5.47416556e+02, 3.70465686e+02,\n",
       "        4.82546275e+02, 6.82721510e+02, 4.12059325e+02, 4.11478151e+02,\n",
       "        3.95528375e+02, 3.97841335e+02, 4.54144905e+02, 5.76271212e+02,\n",
       "        4.73412241e+02, 4.12751360e+02, 4.55635217e+02, 3.70425029e+02,\n",
       "        5.65937361e+02, 4.33766064e+02, 5.83830420e+02, 3.67544203e+02,\n",
       "        5.41247623e+02, 3.92000589e+02, 3.76643433e+02, 5.20069677e+02,\n",
       "        3.70446778e+02, 4.43413024e+02, 4.33997228e+02, 3.14617351e+02,\n",
       "        4.60766945e+02, 4.06860214e+02, 1.05664063e+03, 4.58339949e+02,\n",
       "        3.75236537e+02, 4.36626178e+02, 4.05653611e+02, 3.91570018e+02,\n",
       "        4.24384582e+02, 4.96497138e+02, 6.75207749e+02, 4.04373555e+02,\n",
       "        4.33250931e+02, 6.07910261e+02, 4.00387889e+02, 3.94573871e+02,\n",
       "        6.15015664e+02, 3.65753250e+02, 4.27103578e+02, 5.83653761e+02,\n",
       "        4.48182126e+02, 3.85681799e+02, 3.82302725e+02, 3.88428423e+02,\n",
       "        4.46124211e+02, 3.74537440e+02, 4.36425643e+02, 4.60882035e+02,\n",
       "        5.58621917e+02, 3.99713822e+02, 3.97285138e+02, 4.60470487e+02,\n",
       "        4.50891801e+02, 5.31948154e+02, 5.95980004e+02, 5.98859608e+02,\n",
       "        3.75361240e+02, 3.96071383e+02, 4.41468353e+02, 3.10216771e+02,\n",
       "        6.18561717e+02, 4.16596305e+02, 4.21286294e+02, 4.12431963e+02,\n",
       "        3.61106517e+02, 4.68754982e+02, 5.63298273e+02, 3.99683867e+02,\n",
       "        3.74834062e+02, 4.39383581e+02, 6.91987613e+02, 3.42030788e+02,\n",
       "        4.47389084e+02, 3.92385461e+02, 3.74810817e+02, 3.73943441e+02,\n",
       "        4.82048408e+02, 4.16475744e+02, 3.98396199e+02, 5.71600897e+02,\n",
       "        5.20080493e+02, 3.88401527e+02, 4.22699869e+02, 4.05079712e+02,\n",
       "        3.75583781e+02, 3.19436233e+02, 3.47633926e+02, 3.67717724e+02,\n",
       "        3.09419871e+02, 4.46377791e+02, 3.91329201e+02, 4.29891195e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.data[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eam-abi-robustness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
