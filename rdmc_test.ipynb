{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import os\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    # set this to \"torch\", \"tensorflow\", or \"jax\"\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "import numpy as np\n",
    "import bayesflow as bf\n",
    "import keras\n",
    "from numba import jit, njit, prange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit # (nopython=True, parallel=True)\n",
    "def find_min_and_argmin(arr):\n",
    "    \"\"\"\n",
    "    Combined minimum value and index finder for 2D array along axis 0.\n",
    "    More efficient than separate min and argmin operations.\n",
    "    \"\"\"\n",
    "    rows, cols = arr.shape\n",
    "    min_vals = np.empty(cols, dtype=arr.dtype)\n",
    "    min_idxs = np.empty(cols, dtype=np.int64)\n",
    "    \n",
    "    for j in prange(cols):\n",
    "        min_val = arr[0, j]\n",
    "        min_idx = 0\n",
    "        for i in range(1, rows):\n",
    "            if arr[i, j] < min_val:\n",
    "                min_val = min_val\n",
    "                min_idx = i\n",
    "        min_vals[j] = min_val\n",
    "        min_idxs[j] = min_idx\n",
    "    \n",
    "    return min_vals, min_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit #(nopython=True, parallel=True)\n",
    "def dmc_experiment_simple(mu, b, s, t0, num_obs, t_max=1000):\n",
    "    num_accumulators = mu.shape[0]\n",
    "\n",
    "    fpt = np.zeros((num_accumulators, num_obs))\n",
    "    \n",
    "    for n in prange(num_obs):\n",
    "        for i in prange(num_accumulators):\n",
    "            xt = 0.0\n",
    "            for t in range(t_max):\n",
    "                xt += mu[i, t] + (s * np.random.randn())\n",
    "                if xt > b:\n",
    "                    fpt[i, n] = t\n",
    "                    break\n",
    "\n",
    "    rt, resp = find_min_and_argmin(fpt)\n",
    "    rt += t0\n",
    "\n",
    "    return resp, rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_fun(mu_c_loc=2, mu_c_scale=1, rng=None):\n",
    "    num_accumulators = 2\n",
    "\n",
    "    amp = 20.0\n",
    "    tau = 30\n",
    "    a_shape = 2.0\n",
    "    b = 100.0\n",
    "    t0 = 300.0\n",
    "    s = 4.0\n",
    "    mu_c = rng.gamma(mu_c_loc, mu_c_scale, size=num_accumulators)\n",
    "\n",
    "    return {\"mu_c\": mu_c, \"amp\": amp, \"tau\": tau, \"a_shape\": a_shape, \"b\": b, \"s\": s, \"t0\": t0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_number_obs(batch_shape, rng=None):\n",
    "    return {\"num_obs\": np.tile(rng.integers(200, 300), batch_shape)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator_fun(mu_c, b, s, t0, amp, tau, a_shape, num_obs, t_max=1000, rng=None):\n",
    "    t = np.arange(1, t_max + 1, 1)\n",
    "\n",
    "    eq4 = (\n",
    "        amp\n",
    "        * np.exp(-t / tau)\n",
    "        * (np.exp(1) * t / (a_shape - 1) / tau) ** (a_shape - 1)\n",
    "    )\n",
    "\n",
    "    data = np.zeros((num_obs, 3))\n",
    "\n",
    "    num_obs_h = int(num_obs/2)\n",
    "\n",
    "    for m, k in enumerate((1, -1)):\n",
    "        mu = k * mu_c[:, None] + eq4 * ((a_shape - 1) / t - 1 / tau)\n",
    "        rt, resp = dmc_experiment_simple(mu, b, s, t0, num_obs_h, t_max)\n",
    "        data[(m * num_obs_h):((m + 1) * num_obs_h), 0] = rt\n",
    "        data[(m * num_obs_h):((m + 1) * num_obs_h), 1] = resp\n",
    "        data[(m * num_obs_h):((m + 1) * num_obs_h), 2] = k\n",
    "\n",
    "    return {\"x\": data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.utils import batched_call, tree_stack\n",
    "\n",
    "def batch_simulator(batch_shape, simulator_fun, **kwargs):\n",
    "    data = batched_call(simulator_fun, batch_shape, kwargs=kwargs, flatten=True)\n",
    "    data = tree_stack(data, axis=0, numpy=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from bayesflow.types import Shape\n",
    "\n",
    "class DmcSimulator(bf.simulators.Simulator):\n",
    "    def __init__(self, prior_fun: Callable, design_fun: Callable, simulator_fun: Callable):\n",
    "        self.prior_fun = prior_fun\n",
    "        self.design_fun = design_fun\n",
    "        self.simulator_fun = simulator_fun\n",
    "\n",
    "\n",
    "    def sample(self, batch_shape: Shape, **kwargs) -> dict[str, np.ndarray]:\n",
    "        prior_dict = self.prior_fun(batch_shape)\n",
    "\n",
    "        design_dict = self.design_fun(batch_shape)\n",
    "\n",
    "        design_dict.update(**kwargs)\n",
    "\n",
    "        sims_dict = self.simulator_fun(batch_shape, **prior_dict, **design_dict)\n",
    "\n",
    "        data = prior_dict | design_dict | sims_dict\n",
    "\n",
    "        data = {\n",
    "            key: np.expand_dims(value, axis=-1) if np.ndim(value) == 1 else value for key, value in data.items()\n",
    "        }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = DmcSimulator(\n",
    "    prior_fun=partial(batch_simulator, simulator_fun=partial(prior_fun, rng=RNG)),\n",
    "    design_fun=partial(random_number_obs, rng=RNG),\n",
    "    simulator_fun=partial(batch_simulator, simulator_fun=simulator_fun)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 ms ± 17.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "sample_data = simulator.sample((64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = simulator.sample((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of sample_data:\n",
      "\t <class 'dict'>\n",
      "Keys of sample_data:\n",
      "\t dict_keys(['mu_c', 'amp', 'tau', 'a_shape', 'b', 's', 't0', 'num_obs', 'x'])\n",
      "Types of sample_data values:\n",
      "\t {'mu_c': <class 'numpy.ndarray'>, 'amp': <class 'numpy.ndarray'>, 'tau': <class 'numpy.ndarray'>, 'a_shape': <class 'numpy.ndarray'>, 'b': <class 'numpy.ndarray'>, 's': <class 'numpy.ndarray'>, 't0': <class 'numpy.ndarray'>, 'num_obs': <class 'numpy.ndarray'>, 'x': <class 'numpy.ndarray'>}\n",
      "Shapes of sample_data values:\n",
      "\t {'mu_c': (10, 2), 'amp': (10, 1), 'tau': (10, 1), 'a_shape': (10, 1), 'b': (10, 1), 's': (10, 1), 't0': (10, 1), 'num_obs': (10, 1), 'x': (10, 237, 3)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of sample_data:\\n\\t\", type(sample_data))\n",
    "print(\"Keys of sample_data:\\n\\t\", sample_data.keys())\n",
    "print(\"Types of sample_data values:\\n\\t\", {k: type(v) for k, v in sample_data.items()})\n",
    "print(\"Shapes of sample_data values:\\n\\t\", {k: v.shape for k, v in sample_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter = (\n",
    "    bf.data_adapters.DataAdapter()\n",
    "    .to_array()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .concatenate([\"mu_c\"], into=\"inference_variables\")\n",
    ")\n",
    "\n",
    "data_adapter = data_adapter.concatenate([\"num_obs\"], into=\"inference_conditions\")\n",
    "\n",
    "data_adapter = data_adapter.as_set([\"x\"]).concatenate(\n",
    "    [\"x\"], into=\"summary_variables\"\n",
    ")\n",
    "\n",
    "data_adapter = data_adapter.keep(\n",
    "    [\"inference_variables\", \"inference_conditions\", \"summary_variables\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = bf.networks.SetTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_network = bf.networks.FlowMatching(\n",
    "    subnet=\"mlp\",\n",
    "    use_optimal_transport=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator = bf.ContinuousApproximator(\n",
    "    summary_network=summary_network,\n",
    "    inference_network=inference_network,\n",
    "    data_adapter=data_adapter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Building dataset from simulator instance of DmcSimulator.\n",
      "INFO:bayesflow:Using 32 data loading workers.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m  2/500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:44\u001b[0m 12s/step - loss: 8.9624 - loss/inference_loss: 8.9624"
     ]
    }
   ],
   "source": [
    "history = approximator.fit(\n",
    "    epochs=5,\n",
    "    num_batches=500,\n",
    "    batch_size=64,\n",
    "    # memory_budget=\"8 GiB\",\n",
    "    simulator=simulator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow_plots import plot_z_score_contraction, plot_recovery\n",
    "from utils import convert_samples_posterior, convert_samples_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"v_intercept\", \"v_slope\", \"s_true\", \"b\", \"t0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_dict = simulator.sample(\n",
    "    batch_shape=(100,), num_obs=np.tile([500], (100,))\n",
    ")\n",
    "\n",
    "prior_samples = convert_samples_prior(forward_dict, param_names)\n",
    "\n",
    "sample_dict = {k: v for k, v in forward_dict.items() if k not in data_adapter.keys[\"inference_variables\"]}\n",
    "\n",
    "posterior_samples_sens = convert_samples_posterior(approximator.sample(\n",
    "    conditions=sample_dict, num_samples=100\n",
    "), param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_z_score_contraction(posterior_samples_sens, prior_samples, param_names=param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_recovery(np.swapaxes(posterior_samples_sens, 0, 1), prior_samples, param_names=param_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eam-abi-robustness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
